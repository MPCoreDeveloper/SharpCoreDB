# Storage Engine Architecture Analysis

## Current State (2025-12-16)

### âœ… What EXISTS and WORKS:

1. **IStorageEngine Interface** (`Interfaces/IStorageEngine.cs`)
   - Well-defined contract for storage engines
   - Methods: Insert, InsertBatch, Update, Delete, Read
   - Transaction support: BeginTransaction, CommitAsync, Rollback
   - Metrics tracking: GetMetrics()

2. **AppendOnlyEngine** (`Storage/Engines/AppendOnlyEngine.cs`)
   - âœ… Fully implemented and working
   - Wraps existing `IStorage` for append-only operations
   - Returns file offset as storage reference
   - Uses `storage.AppendBytes()` for inserts
   - Update = append new version (old becomes stale)
   - Delete = logical (mark in index layer)
   - **Performance:** ~50-100ms for 10K inserts

3. **PageBasedEngine** (`Storage/Engines/PageBasedEngine.cs`)
   - âœ… Fully implemented and working
   - Standalone 8KB page management
   - Returns encoded reference: [48-bit pageId][16-bit slotIndex]
   - Uses `PageManager` for page allocation
   - Update = in-place modification
   - Delete = slot marking (no tombstones)
   - **Performance:** Designed for OLTP (updates 10-100x faster)

4. **StorageEngineFactory** (`Storage/Engines/StorageEngineFactory.cs`)
   - âœ… Factory pattern for creating engines
   - Supports: AppendOnly, PageBased, Hybrid
   - Handles dependency injection correctly

5. **PageManager** (`Storage/Hybrid/PageManager.cs`)
   - âœ… Core page-based storage implementation
   - 8KB fixed pages with slot arrays
   - Free list allocator
   - Page cache with CLOCK eviction
   - **Methods:**
     - `FindPageWithSpace(tableId, size)` â†’ PageId
     - `InsertRecord(pageId, data)` â†’ RecordId
     - `ReadRecord(pageId, recordId)` â†’ byte[]
     - `UpdateRecord(pageId, recordId, newData)`
     - `DeleteRecord(pageId, recordId)`

### âŒ What is MISSING:

1. **Table Class Storage Engine Routing**
   - âŒ Table has `StorageMode` property but NEVER uses it
   - âŒ All operations hardcoded to append-only columnar storage
   - âŒ No engine initialization based on StorageMode
   - âŒ No routing logic in Insert/Select/Update/Delete

2. **Storage Reference Type Mismatch**
   - AppendOnly returns: file offset (long)
   - PageBased returns: encoded pageId+slotIndex (long)
   - âŒ Table doesn't distinguish between reference types
   - âŒ Reading with wrong engine = corruption

3. **SqlParser Integration Gap**
   - âœ… Parses `STORAGE = PAGE_BASED` clause correctly
   - âœ… Sets `table.StorageMode` property
   - âœ… Creates `.pages` file
   - âŒ Never initializes storage engine!
   - âŒ Table falls back to append-only code with `.pages` extension = **DISASTER**

## Root Cause of Performance Issues

**When you use `STORAGE = PAGE_BASED`:**

1. SqlParser creates `.pages` file âœ…
2. SqlParser sets `table.StorageMode = PageBased` âœ…
3. Table.Insert() ignores StorageMode âŒ
4. Table.Insert() calls `storage.AppendBytes("users.pages", data)` âŒ
5. AppendOnly code tries to write to `.pages` file âŒ
6. File format mismatch causes corruption/overhead âŒ
7. **Result:** 32-36x SLOWER than SQLite! ðŸ’¥

## Implementation Strategy

### Phase 1: Storage Engine Routing (Steps 1-2)

```csharp
// Table.cs - Add private field
private IStorageEngine? _storageEngine;

// Table.cs - Initialize engine based on StorageMode
private IStorageEngine GetOrCreateStorageEngine()
{
    if (_storageEngine != null) 
        return _storageEngine;
    
    _storageEngine = StorageMode switch
    {
        StorageMode.Columnar => StorageEngineFactory.CreateEngine(
            StorageEngineType.AppendOnly, storage, Path.GetDirectoryName(DataFile)!),
        
        StorageMode.PageBased => StorageEngineFactory.CreateEngine(
            StorageEngineType.PageBased, null, Path.GetDirectoryName(DataFile)!),
        
        _ => throw new NotSupportedException($"Storage mode {StorageMode} not supported")
    };
    
    return _storageEngine;
}
```

### Phase 2: CRUD Routing (Steps 3-6)

**Insert:**
```csharp
public void Insert(Dictionary<string, object> row)
{
    var engine = GetOrCreateStorageEngine();
    var serializedData = SerializeRow(row);
    var storageRef = engine.Insert(Name, serializedData);
    
    // Update indexes with storageRef
    UpdateIndexes(row, storageRef);
}
```

**Select:**
```csharp
public List<Dictionary<string, object>> Select(string? where, ...)
{
    var engine = GetOrCreateStorageEngine();
    
    // Get storage refs from index or full scan
    var refs = FindMatchingRefs(where);
    
    var results = new List<Dictionary<string, object>>();
    foreach (var ref in refs)
    {
        var data = engine.Read(Name, ref);
        if (data != null)
        {
            results.Add(DeserializeRow(data));
        }
    }
    return results;
}
```

**Update (Columnar = append, PageBased = in-place):**
```csharp
public void Update(string? where, Dictionary<string, object> updates)
{
    var engine = GetOrCreateStorageEngine();
    var refsToUpdate = FindMatchingRefs(where);
    
    foreach (var oldRef in refsToUpdate)
    {
        if (StorageMode == StorageMode.Columnar)
        {
            // Append-only: write new version, mark old as stale
            var row = ReadRow(oldRef);
            ApplyUpdates(row, updates);
            var newRef = engine.Insert(Name, SerializeRow(row));
            UpdateIndexes(row, newRef, oldRef); // Replace old ref
        }
        else // PageBased
        {
            // In-place update
            var row = ReadRow(oldRef);
            ApplyUpdates(row, updates);
            engine.Update(Name, oldRef, SerializeRow(row));
            // Ref stays same, just update indexes if needed
        }
    }
}
```

## Expected Performance After Implementation

### OLTP Workloads (PAGE_BASED):
- Bulk Insert: **100-200ms** (was 2776ms!) - 14x faster
- Lookups: **20-50ms** (was 233ms!) - 5x faster
- Updates: **50-150ms** (was N/A) - In-place updates!
- Mixed Workload: **200-500ms** (was 1803ms!) - 4x faster

### OLAP Workloads (COLUMNAR):
- Bulk Insert: **80-150ms** - Already optimized
- SIMD Aggregates: **2-10ms** - Already perfect! âœ…
- Full Table Scans: **Fast** - Sequential reads

## Files to Modify

1. `DataStructures/Table.cs` - Add storage engine field + initialization
2. `DataStructures/Table.CRUD.cs` - Route all CRUD to engine
3. `Services/SqlParser.DDL.cs` - Call Table.InitializeStorageEngine()
4. `Storage/StorageMigrator.cs` - Complete COLUMNAR â†” PAGE_BASED migration
5. `SharpCoreDB.Tests/PageBasedStorageTests.cs` - New comprehensive tests
6. `SharpCoreDB.Benchmarks/ComprehensiveComparison.cs` - Separate OLTP/OLAP benchmarks

## Next Steps

1. âœ… **Step 1 COMPLETE:** Architecture analyzed
2. ðŸ”„ **Step 2 NEXT:** Implement storage engine router in Table class
3. ðŸ“‹ **Step 3-6:** Route CRUD operations
4. ðŸ“‹ **Step 7-9:** SQL integration + migration
5. ðŸ“‹ **Step 10-12:** Tests, benchmarks, docs
